{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from tqdm import tqdm\n",
    "from pytorch_fid import fid_score\n",
    "from torchvision import transforms\n",
    "from lpips import LPIPS\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class FaceGenerationBenchmark:\n",
    "    def __init__(self, real_images_path, gan_generated_path, sdxl_generated_path, batch_size=32):\n",
    "        \"\"\"\n",
    "        Initialize the benchmarking framework\n",
    "        \n",
    "        Args:\n",
    "            real_images_path: Path to directory containing real face images\n",
    "            gan_generated_path: Path to directory containing GAN-generated faces\n",
    "            sdxl_generated_path: Path to directory containing SDXL-generated faces\n",
    "            batch_size: Batch size for processing images\n",
    "        \"\"\"\n",
    "        self.real_images_path = real_images_path\n",
    "        self.gan_generated_path = gan_generated_path\n",
    "        self.sdxl_generated_path = sdxl_generated_path\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Initialize LPIPS model\n",
    "        self.lpips_model = LPIPS(net='alex').cuda()\n",
    "        \n",
    "        # Define image transforms\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def load_images(self, path):\n",
    "        \"\"\"Load and preprocess images from directory\"\"\"\n",
    "        images = []\n",
    "        for img_name in os.listdir(path):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(path, img_name)\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = self.transform(img)\n",
    "                images.append(img)\n",
    "        return torch.stack(images)\n",
    "    \n",
    "    def calculate_fid(self, real_features, generated_features):\n",
    "        \"\"\"Calculate FID score between real and generated image features\"\"\"\n",
    "        mu1, sigma1 = real_features.mean(axis=0), np.cov(real_features, rowvar=False)\n",
    "        mu2, sigma2 = generated_features.mean(axis=0), np.cov(generated_features, rowvar=False)\n",
    "        \n",
    "        ssdiff = np.sum((mu1 - mu2) ** 2)\n",
    "        covmean = linalg.sqrtm(sigma1.dot(sigma2))\n",
    "        \n",
    "        if np.iscomplexobj(covmean):\n",
    "            covmean = covmean.real\n",
    "            \n",
    "        fid = ssdiff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
    "        return fid\n",
    "    \n",
    "    def calculate_lpips(self, images1, images2):\n",
    "        \"\"\"Calculate average LPIPS distance between two sets of images\"\"\"\n",
    "        total_distance = 0\n",
    "        num_pairs = min(len(images1), len(images2))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, num_pairs, self.batch_size):\n",
    "                batch1 = images1[i:i+self.batch_size].cuda()\n",
    "                batch2 = images2[i:i+self.batch_size].cuda()\n",
    "                distance = self.lpips_model(batch1, batch2)\n",
    "                total_distance += distance.sum().item()\n",
    "        \n",
    "        return total_distance / num_pairs\n",
    "    \n",
    "    def run_benchmark(self):\n",
    "        \"\"\"Run complete benchmarking suite\"\"\"\n",
    "        print(\"Loading images...\")\n",
    "        real_images = self.load_images(self.real_images_path)\n",
    "        gan_images = self.load_images(self.gan_generated_path)\n",
    "        sdxl_images = self.load_images(self.sdxl_generated_path)\n",
    "        \n",
    "        # Calculate FID scores\n",
    "        print(\"Calculating FID scores...\")\n",
    "        inception = torchvision.models.inception_v3(pretrained=True, transform_input=False).cuda()\n",
    "        inception.eval()\n",
    "        \n",
    "        def get_features(images):\n",
    "            features = []\n",
    "            with torch.no_grad():\n",
    "                for i in range(0, len(images), self.batch_size):\n",
    "                    batch = images[i:i+self.batch_size].cuda()\n",
    "                    feat = inception(batch)[0].squeeze()\n",
    "                    features.append(feat.cpu().numpy())\n",
    "            return np.concatenate(features)\n",
    "        \n",
    "        real_features = get_features(real_images)\n",
    "        gan_features = get_features(gan_images)\n",
    "        sdxl_features = get_features(sdxl_images)\n",
    "        \n",
    "        gan_fid = self.calculate_fid(real_features, gan_features)\n",
    "        sdxl_fid = self.calculate_fid(real_features, sdxl_features)\n",
    "        \n",
    "        # Calculate LPIPS scores\n",
    "        print(\"Calculating LPIPS scores...\")\n",
    "        gan_lpips = self.calculate_lpips(real_images, gan_images)\n",
    "        sdxl_lpips = self.calculate_lpips(real_images, sdxl_images)\n",
    "        \n",
    "        results = {\n",
    "            'GAN': {\n",
    "                'FID': gan_fid,\n",
    "                'LPIPS': gan_lpips\n",
    "            },\n",
    "            'SDXL': {\n",
    "                'FID': sdxl_fid,\n",
    "                'LPIPS': sdxl_lpips\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "def generate_benchmark_report(results):\n",
    "    \"\"\"Generate a formatted report of benchmark results\"\"\"\n",
    "    report = \"Face Generation Model Benchmark Results\\n\"\n",
    "    report += \"====================================\\n\\n\"\n",
    "    \n",
    "    for model, metrics in results.items():\n",
    "        report += f\"{model} Model:\\n\"\n",
    "        report += f\"  FID Score: {metrics['FID']:.4f}\\n\"\n",
    "        report += f\"  LPIPS Score: {metrics['LPIPS']:.4f}\\n\\n\"\n",
    "    \n",
    "    # Add interpretation\n",
    "    report += \"Interpretation:\\n\"\n",
    "    report += \"- Lower scores are better for both metrics\\n\"\n",
    "    report += \"- FID measures overall distribution similarity\\n\"\n",
    "    report += \"- LPIPS measures perceptual similarity\\n\"\n",
    "    \n",
    "    return report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
